{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba98e7d-cf2f-41e3-9fd8-6a70fd13177b",
   "metadata": {},
   "source": [
    "## LAB ACTIVITY 17\n",
    "## NAME : VITHUN GS; REG NO : 22MID0090; COURSE CODE: CSI3007; LAB : L7+L8;\n",
    "## DATE : 03/10/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78212e57-f24d-47b6-bbe4-0fa15cb06408",
   "metadata": {},
   "source": [
    "# Essential Data Analysis Techniques in Python: DataFrames, indexing, grouping, merging, and pivot tables in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6329b3b-8ecb-4776-8917-8a5738154639",
   "metadata": {},
   "source": [
    "#### 1.Creating DataFrames (different ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f4dad7-6b1a-430a-90e0-b3072fbc32a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from dictionary of lists:\n",
      "      Name  Age  Score\n",
      "0  Sonali   30     92\n",
      "1    Mahi   25     87\n",
      "2  Hardik   28     95 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-1\n",
    "import pandas as pd  # Importing pandas for data manipulation\n",
    "import numpy as np   # Importing numpy for numerical operations\n",
    "\n",
    "# 1. From dictionary of lists\n",
    "\n",
    "# Creating a dictionary where each key corresponds to a column\n",
    "data1 = {\"Name\": [\"Sonali\", \"Mahi\", \"Hardik\"],\n",
    "         \"Age\": [30, 25, 28],\n",
    "         \"Score\": [92, 87, 95]}\n",
    "\n",
    "# Converting the dictionary into a DataFrame\n",
    "df1 = pd.DataFrame(data1)\n",
    "print(\"DataFrame from dictionary of lists:\\n\", df1, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ae56ed-cb97-459d-b332-3ddc4fc5e253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from dictionary of Series:\n",
      "         Math  Science\n",
      "Sonali    95       90\n",
      "Dhoni     88       90\n",
      "Pandya    82       85 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK-2\n",
    "# 2. From dictionary of Series\n",
    "\n",
    "# Creating a dictionary where each value is a pandas Series\n",
    "# The index defines the row labels\n",
    "data2 = {\"Math\": pd.Series([95, 88, 82], index=[\"Sonali\", \"Dhoni\", \"Pandya\"]),\n",
    "         \"Science\": pd.Series([90, 90, 85], index=[\"Sonali\", \"Dhoni\", \"Pandya\"])}\n",
    "\n",
    "# Converting the dictionary of Series into a DataFrame\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"DataFrame from dictionary of Series:\\n\", df2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c56a3a3-7992-4dfc-9aa6-6b34796cdadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from NumPy array:\n",
      "    Col1  Col2  Col3\n",
      "0    10    11    12\n",
      "1    13    14    15\n",
      "2    16    17    18 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK-3\n",
    "# 3. From NumPy array\n",
    "\n",
    "# Creating a 3x3 NumPy array with values 10 to 18 (reshaped into 3 rows, 3 columns)\n",
    "array_data = np.arange(10, 19).reshape(3, 3)\n",
    "\n",
    "# Converting the NumPy array into a DataFrame with column names\n",
    "df3 = pd.DataFrame(array_data,\n",
    "                   columns=[\"Col1\", \"Col2\", \"Col3\"])\n",
    "print(\"DataFrame from NumPy array:\\n\", df3, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0755e-db88-4f4d-b4cd-696afa27ee32",
   "metadata": {},
   "source": [
    "#### 2. Accessing rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17f7fefe-0502-4901-8057-e4560501784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age  Score\n",
      "0  Sonali   28     91\n",
      "1    Mahi   31     85\n",
      "2  Hardik   26     89\n",
      "3    Axar   29     94 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-4\n",
    "# Program 2: Accessing rows and columns\n",
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Creating a dictionary with new data\n",
    "data = {\"Name\": [\"Sonali\", \"Mahi\", \"Hardik\", \"Axar\"],\n",
    "        \"Age\": [28, 31, 26, 29],\n",
    "        \"Score\": [91, 85, 89, 94]}\n",
    "\n",
    "# Converting dictionary to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0eaebc5-0f81-4eee-96d9-13f4d46e34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing single column (Score):\n",
      " 0    91\n",
      "1    85\n",
      "2    89\n",
      "3    94\n",
      "Name: Score, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access a single column\n",
    "\n",
    "# Selecting the 'Score' column; returns a Series\n",
    "print(\"Accessing single column (Score):\\n\", df[\"Score\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5776ed68-a080-47ab-ac5f-1b84bcf618a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing multiple columns:\n",
      "      Name  Age\n",
      "0  Sonali   28\n",
      "1    Mahi   31\n",
      "2  Hardik   26\n",
      "3    Axar   29 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access multiple columns\n",
    "\n",
    "# Selecting 'Name' and 'Age' columns; returns a DataFrame\n",
    "print(\"Accessing multiple columns:\\n\", df[[\"Name\", \"Age\"]], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2951334-eefc-4c42-b238-21655ac4cc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access row using loc:\n",
      " Name     Hardik\n",
      "Age          26\n",
      "Score        89\n",
      "Name: 2, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access row by index label using loc\n",
    "\n",
    "# loc uses the row labels (default is 0,1,2,...)\n",
    "print(\"Access row using loc:\\n\", df.loc[2], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1a26c42-3d1f-45be-8b39-8f01089a9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access row using iloc:\n",
      " Name     Mahi\n",
      "Age        31\n",
      "Score      85\n",
      "Name: 1, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access row by integer location using iloc\n",
    "\n",
    "# iloc uses integer position to access rows\n",
    "print(\"Access row using iloc:\\n\", df.iloc[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1841e-86af-43e9-ab50-285f94426358",
   "metadata": {},
   "source": [
    "#### 3. Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "730ee54d-6e4f-47ab-a0fa-6965962fea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age  Score\n",
      "0    Sona   31     95\n",
      "1    Mahi   26     92\n",
      "2  Jadeja   29     88\n",
      "3  Hardik   24     90\n",
      "4   Rohit   27     87 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-5\n",
    "import pandas as pd  # Importing pandas library\n",
    "\n",
    "# Creating a dictionary with new data\n",
    "data = {\"Name\": [\"Sona\", \"Mahi\", \"Jadeja\", \"Hardik\", \"Rohit\"],\n",
    "        \"Age\": [31, 26, 29, 24, 27],\n",
    "        \"Score\": [95, 92, 88, 90, 87]}\n",
    "\n",
    "# Converting dictionary into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25fd2508-cd71-4913-8406-324fd4471a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three rows:\n",
      "      Name  Age  Score\n",
      "0    Sona   31     95\n",
      "1    Mahi   26     92\n",
      "2  Jadeja   29     88 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Slicing rows using standard Python slicing\n",
    "\n",
    "# Select the first three rows (0,1,2)\n",
    "print(\"First three rows:\\n\", df[:3], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77eac336-5e6b-434b-83a7-c3db290feee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows 1 to 3:\n",
      "      Name  Age  Score\n",
      "1    Mahi   26     92\n",
      "2  Jadeja   29     88\n",
      "3  Hardik   24     90 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Slicing specific rows using loc\n",
    "\n",
    "# loc includes both start and end index (rows 1 to 3)\n",
    "print(\"Rows 1 to 3:\\n\", df.loc[1:3], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "671e31bc-d94b-47ae-9e4c-474d6d3e23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Name and Score:\n",
      "      Name  Score\n",
      "0    Sona     95\n",
      "1    Mahi     92\n",
      "2  Jadeja     88\n",
      "3  Hardik     90\n",
      "4   Rohit     87 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Slicing specific columns\n",
    "\n",
    "# Select all rows (:) but only 'Name' and 'Score' columns\n",
    "print(\"Columns Name and Score:\\n\", df.loc[:, [\"Name\", \"Score\"]], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "188821e9-db9c-49f7-b939-89c3591df9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where Score > 88:\n",
      "      Name  Age  Score\n",
      "0    Sona   31     95\n",
      "1    Mahi   26     92\n",
      "3  Hardik   24     90 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conditional selection\n",
    "\n",
    "# Select rows where 'Score' > 88\n",
    "print(\"Rows where Score > 88:\\n\", df[df[\"Score\"] > 88], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c0ba3-cd50-40e0-8fe8-c0532a0a9d34",
   "metadata": {},
   "source": [
    "#### 4. Adding, Updating, and Deleting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0890133-fb10-4338-a677-a7a424a358f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age\n",
      "0  Sonali   30\n",
      "1    Mahi   25\n",
      "2  Hardik   28 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-6\n",
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Creating a DataFrame with initial data\n",
    "df = pd.DataFrame({\"Name\": [\"Sonali\", \"Mahi\", \"Hardik\"],\n",
    "                   \"Age\": [30, 25, 28]})\n",
    "print(\"Original DataFrame:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b77963f-74f4-4732-9ac1-3faf6621b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding Score column:\n",
      "      Name  Age  Score\n",
      "0  Sonali   30     92\n",
      "1    Mahi   25     87\n",
      "2  Hardik   28     95 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column\n",
    "\n",
    "# Adding a 'Score' column with new values\n",
    "df[\"Score\"] = [92, 87, 95]\n",
    "print(\"After adding Score column:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a67214bc-dfe7-49ae-8510-d022799e4644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After updating Age of Eva:\n",
      "      Name  Age  Score\n",
      "0  Sonali   30     92\n",
      "1    Mahi   26     87\n",
      "2  Hardik   28     95 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Updating values\n",
    "\n",
    "# Updating the Age of the second row (Mahi) using at\n",
    "df.at[1, \"Age\"] = 26\n",
    "print(\"After updating Age of Eva:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdd6188d-f557-4dcd-943c-6250e7c2c326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deleting Score column:\n",
      "      Name  Age\n",
      "0  Sonali   30\n",
      "1    Mahi   26\n",
      "2  Hardik   28 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deleting a column\n",
    "\n",
    "# Dropping the 'Score' column; axis=1 indicates column\n",
    "df = df.drop(\"Score\", axis=1)\n",
    "print(\"After deleting Score column:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ce1218d-62ca-4963-a39b-0bf74521aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deleting row with index 2:\n",
      "      Name  Age\n",
      "0  Sonali   30\n",
      "1    Mahi   26 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deleting a row\n",
    "\n",
    "# Dropping the row with index 2 (Hardik); axis=0 indicates row\n",
    "df = df.drop(2, axis=0)\n",
    "print(\"After deleting row with index 2:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9538ee-76ba-4d4b-86cc-e88d1aa376a2",
   "metadata": {},
   "source": [
    "#### 5. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f1ba095-8fc3-4278-ba39-9d0b22631ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with NaN values:\n",
      "      Name   Age  Score\n",
      "0  Sonali  30.0   92.0\n",
      "1    Mahi   NaN   87.0\n",
      "2  Bumrah  28.0    NaN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-7\n",
    "import pandas as pd  # Import pandas for data handling\n",
    "import numpy as np   # Import numpy for NaN representation\n",
    "\n",
    "# Creating a DataFrame with some missing values (NaN)\n",
    "df = pd.DataFrame({\"Name\": [\"Sonali\", \"Mahi\", \"Bumrah\"],\n",
    "                   \"Age\": [30, np.nan, 28],\n",
    "                   \"Score\": [92, 87, np.nan]})\n",
    "print(\"Original DataFrame with NaN values:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ce3fa92-8112-44f0-b205-2910e8f80a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect missing values:\n",
      "     Name    Age  Score\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2  False  False   True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detect missing values\n",
    "\n",
    "# isnull() returns True for NaN values, False otherwise\n",
    "print(\"Detect missing values:\\n\", df.isnull(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8764339e-9365-4c83-a2c6-50b8bb76ebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill missing values:\n",
      "      Name   Age  Score\n",
      "0  Sonali  30.0   92.0\n",
      "1    Mahi   0.0   87.0\n",
      "2  Bumrah  28.0    0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "\n",
    "# fillna(0) replaces all NaN values with 0\n",
    "print(\"Fill missing values:\\n\", df.fillna(0), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dad167d-a42b-4c39-9d60-27b6664fec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop rows with missing values:\n",
      "      Name   Age  Score\n",
      "0  Sonali  30.0   92.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "\n",
    "# dropna() removes any row that contains at least one NaN\n",
    "print(\"Drop rows with missing values:\\n\", df.dropna(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5c811-7bc7-4d30-8bf8-67116b9d8b21",
   "metadata": {},
   "source": [
    "#### 6: Data Alignment and Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b41c682-b21b-4807-85cc-ddb36ee53db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "         Score\n",
      "Sonali     91\n",
      "Mahi       85\n",
      "Hardik     89 \n",
      "\n",
      "DataFrame 2:\n",
      "         Score\n",
      "Axar       88\n",
      "Bumrah     95 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-8\n",
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Creating first DataFrame with scores and custom index\n",
    "df1 = pd.DataFrame({\"Score\": [91, 85, 89]}, index=[\"Sonali\", \"Mahi\", \"Hardik\"])\n",
    "\n",
    "# Creating second DataFrame with some overlapping and some new index\n",
    "df2 = pd.DataFrame({\"Score\": [88, 95]}, index=[\"Axar\", \"Bumrah\"])\n",
    "\n",
    "# Display the original DataFrames\n",
    "print(\"DataFrame 1:\\n\", df1, \"\\n\")\n",
    "print(\"DataFrame 2:\\n\", df2, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc109b8a-a7a0-4c16-bd77-676b89eff48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding df1 and df2:\n",
      "         Score\n",
      "Axar      NaN\n",
      "Bumrah    NaN\n",
      "Hardik    NaN\n",
      "Mahi      NaN\n",
      "Sonali    NaN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatic alignment in arithmetic\n",
    "\n",
    "# Adding two DataFrames; pandas aligns rows by index\n",
    "# Missing indices result in NaN\n",
    "print(\"Adding df1 and df2:\\n\", df1 + df2, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9774dc4-3639-4fd3-a8b2-8932f5145a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reindexed DataFrame:\n",
      "         Score\n",
      "Sonali     91\n",
      "Mahi       85\n",
      "Hardik     89\n",
      "Bumrah      0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reindexing\n",
    "\n",
    "# Reindex df1 to include a new index 'Bumrah', filling missing values with 0\n",
    "df3 = df1.reindex([\"Sonali\", \"Mahi\", \"Hardik\", \"Bumrah\"], fill_value=0)\n",
    "print(\"Reindexed DataFrame:\\n\", df3, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b102af6-c057-4f50-9b52-b7166f5c7198",
   "metadata": {},
   "source": [
    "#### 7. Sorting and Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "407dd30a-b754-4207-8a7d-e19d4613c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age  Score\n",
      "0  Sonali   31     91\n",
      "1    Mahi   26     85\n",
      "2  Hardik   29     89\n",
      "3    Gill   24     90\n",
      "4    Axar   27     87 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-9\n",
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Creating a new DataFrame with updated data\n",
    "data = {\"Name\": [\"Sonali\", \"Mahi\", \"Hardik\", \"Gill\", \"Axar\"],\n",
    "        \"Age\": [31, 26, 29, 24, 27],\n",
    "        \"Score\": [91, 85, 89, 90, 87]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9be8d84-6ba2-4ab1-aee4-70f4affc5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by Score:\n",
      "      Name  Age  Score\n",
      "1    Mahi   26     85\n",
      "4    Axar   27     87\n",
      "2  Hardik   29     89\n",
      "3    Gill   24     90\n",
      "0  Sonali   31     91 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting by column\n",
    "\n",
    "# sort_values sorts the DataFrame based on the 'Score' column\n",
    "print(\"Sorted by Score:\\n\", df.sort_values(by=\"Score\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3adc7ffb-e79b-4a83-b0fd-059774cb5ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score grouped by Age:\n",
      " Age\n",
      "24    90.0\n",
      "26    85.0\n",
      "27    87.0\n",
      "29    89.0\n",
      "31    91.0\n",
      "Name: Score, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping data\n",
    "\n",
    "# groupby groups rows by 'Age' and computes the mean of 'Score' for each group\n",
    "grouped = df.groupby(\"Age\")[\"Score\"].mean()\n",
    "print(\"Average score grouped by Age:\\n\", grouped, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4f4000c6-e6c2-49a3-acd8-afcd46c4b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      " Sonali    Finance\n",
      "Mahi      Finance\n",
      "Hardik         IT\n",
      "Axar           IT\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## TASK-10\n",
    "# Grouping Example\n",
    "# Grouping and Aggregating for Series \n",
    "\n",
    "# Creating Series\n",
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Salary series \n",
    "salary = pd.Series([72000, 68000, 75000, 70000],\n",
    "                   index=[\"Sonali\", \"Mahi\", \"Hardik\", \"Axar\"])\n",
    "\n",
    "# Department for each person (updated names)\n",
    "department = pd.Series([\"Finance\", \"Finance\", \"IT\", \"IT\"],\n",
    "                       index=[\"Sonali\", \"Mahi\", \"Hardik\", \"Axar\"])\n",
    "print(\"Original Series:\\n\",department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed43987e-4bd7-48d3-8f12-1be0b52b4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean salary by department (Series):\n",
      " Finance    70000.0\n",
      "IT         72500.0\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping salaries by department and calculating mean\n",
    "# groupby + mean calculates average salary for each department\n",
    "grouped_series = salary.groupby(department).mean()\n",
    "print(\"Mean salary by department (Series):\\n\", grouped_series, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43cc5b12-30df-4ffd-a229-c0e7bfd38756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Series (just groups, no aggregation):\n",
      " <pandas.core.groupby.generic.SeriesGroupBy object at 0x000001E2BB3B6270> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping by department (no aggregation yet)\n",
    "\n",
    "# groupby returns a GroupBy object; actual aggregation not performed yet\n",
    "grouped_series = salary.groupby(department)\n",
    "print(\"Grouped Series (just groups, no aggregation):\\n\", grouped_series, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50a3a8fc-a36a-491d-ac08-fb71674a45bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance group in Series:\n",
      " Sonali    72000\n",
      "Mahi      68000\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing a specific group\n",
    "\n",
    "# get_group retrieves all entries belonging to a specific group\n",
    "print(\"Finance group in Series:\\n\", grouped_series.get_group(\"Finance\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "679dd1e7-3d6e-40e5-b471-8f924d253dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Series (mean salary per department):\n",
      " Finance    70000.0\n",
      "IT         72500.0\n",
      "dtype: float64 \n",
      "\n",
      "Sum per department:\n",
      " Finance    140000\n",
      "IT         145000\n",
      "dtype: int64 \n",
      "\n",
      "Max per department:\n",
      " Finance    72000\n",
      "IT         75000\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aggregation Example\n",
    "\n",
    "# Aggregation on grouped Series\n",
    "# Compute mean salary per department\n",
    "aggregated_series = grouped_series.mean()\n",
    "print(\"Aggregated Series (mean salary per department):\\n\", aggregated_series, \"\\n\")\n",
    "\n",
    "# Other aggregations\n",
    "print(\"Sum per department:\\n\", grouped_series.sum(), \"\\n\")\n",
    "print(\"Max per department:\\n\", grouped_series.max(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e31a9bef-3838-457d-8078-772c465bd2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Multi Series:\n",
      " Dept     Employee\n",
      "Finance  Sonali      72000\n",
      "         Mahi        68000\n",
      "IT       Hardik      75000\n",
      "         Axar        70000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## TASK-11\n",
    "\n",
    "# Example: Grouping and Aggregating for MultiLevel Series\n",
    "\n",
    "# Creating a MultiIndex for department and employee\n",
    "arrays = [\n",
    "    [\"Finance\", \"Finance\", \"IT\", \"IT\"],  # First level: Dept\n",
    "    [\"Sonali\", \"Mahi\", \"Hardik\", \"Axar\"]   # Second level: Employee\n",
    "]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=(\"Dept\", \"Employee\"))\n",
    "\n",
    "# Creating MultiLevel Series with updated salaries\n",
    "multi_s = pd.Series([72000, 68000, 75000, 70000], index=index)\n",
    "print(\"Original Multi Series:\\n\",multi_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe6e035b-e655-4bbc-8ede-18d1eb6260e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean salary by department (MultiLevel Series):\n",
      " Dept\n",
      "Finance    70000.0\n",
      "IT         72500.0\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by first level (Dept) and calculate mean\n",
    "# level=0 indicates the first level of MultiIndex\n",
    "grouped_multi = multi_s.groupby(level=0).mean()\n",
    "print(\"Mean salary by department (MultiLevel Series):\\n\", grouped_multi, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14724c3f-b24c-46e3-838a-4c05d40f68fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Department Employee  Salary\n",
      "0         HR   Sonali   50000\n",
      "1         HR     Mahi   55000\n",
      "2         IT   Hardik   60000\n",
      "3         IT     Axar   62000\n"
     ]
    }
   ],
   "source": [
    "## TASK-12\n",
    "\n",
    "# Grouping (DataFrame)\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Department\": [\"HR\", \"HR\", \"IT\", \"IT\"],\n",
    "    \"Employee\": [\"Sonali\", \"Mahi\", \"Hardik\", \"Axar\"],\n",
    "    \"Salary\": [50000, 55000, 60000, 62000]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cd367fce-b45c-49dc-b153-039683afd89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped DataFrame (just groups, no aggregation):\n",
      " <pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001E2C9D25730> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping by Department\n",
    "grouped_df = df.groupby(\"Department\")\n",
    "print(\"Grouped DataFrame (just groups, no aggregation):\\n\", grouped_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "001a6057-e247-4da7-869e-081c78046958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR group in DataFrame:\n",
      "   Department Employee  Salary\n",
      "0         HR   Sonali   50000\n",
      "1         HR     Mahi   55000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing one group\n",
    "print(\"HR group in DataFrame:\\n\", grouped_df.get_group(\"HR\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "db4a9d1c-31be-4f40-8f12-1200a5f9499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame (mean salary per department):\n",
      " Department\n",
      "HR    52500.0\n",
      "IT    61000.0\n",
      "Name: Salary, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregating DataFrame \n",
    "\n",
    "# Aggregation on grouped DataFrame\n",
    "# Compute mean salary per department\n",
    "aggregated_df = grouped_df[\"Salary\"].mean()\n",
    "print(\"Aggregated DataFrame (mean salary per department):\\n\", aggregated_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0fc1c5d-f2d5-4628-abe4-21c6829fa3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame (multiple stats):\n",
      "              Salary               \n",
      "               mean     sum    max\n",
      "Department                        \n",
      "HR          52500.0  105000  55000\n",
      "IT          61000.0  122000  62000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple aggregations on DataFrame\n",
    "multi_agg_df = grouped_df.agg({\n",
    "    \"Salary\": [\"mean\", \"sum\", \"max\"]\n",
    "})\n",
    "print(\"Aggregated DataFrame (multiple stats):\\n\", multi_agg_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a69639-a1d2-4638-9e49-777a9cf910bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Department Employee  Salary  Bonus\n",
      "0    Finance   Sonali   72000   8000\n",
      "1    Finance     Mahi   68000   7500\n",
      "2         IT   Hardik   75000   9000\n",
      "3         IT     Axar   70000   8500\n",
      "4    Finance    Rohit   73000   8200\n",
      "5         IT     Gill   71000   8800 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TASK-13\n",
    "import pandas as pd  # Import pandas for data analysis\n",
    "\n",
    "# Creating a DataFrame with Department, Employee, Salary, and Bonus\n",
    "df = pd.DataFrame({\n",
    "    \"Department\": [\"Finance\", \"Finance\", \"IT\", \"IT\", \"Finance\", \"IT\"],\n",
    "    \"Employee\": [\"Sonali\", \"Mahi\", \"Hardik\", \"Axar\", \"Rohit\", \"Gill\"],\n",
    "    \"Salary\": [72000, 68000, 75000, 70000, 73000, 71000],\n",
    "    \"Bonus\": [8000, 7500, 9000, 8500, 8200, 8800]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8687f73e-686f-4610-a3a5-6b7cd6ab5353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups formed:\n",
      " {'Finance': [0, 1, 4], 'IT': [2, 3, 5]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping by Department (no aggregation yet)\n",
    "\n",
    "# groupby forms groups based on 'Department' column\n",
    "grouped = df.groupby(\"Department\")\n",
    "print(\"Groups formed:\\n\", grouped.groups, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3957f64f-f659-494b-9be5-0fa1baffe605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance group:\n",
      "   Department Employee  Salary  Bonus\n",
      "0    Finance   Sonali   72000   8000\n",
      "1    Finance     Mahi   68000   7500\n",
      "4    Finance    Rohit   73000   8200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access a specific group using get_group()\n",
    "print(\"Finance group:\\n\", grouped.get_group(\"Finance\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06298e47-a335-49dc-abab-0ae17fa78245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Salary per Department:\n",
      " Department\n",
      "Finance    71000.0\n",
      "IT         72000.0\n",
      "Name: Salary, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregating after grouping\n",
    "\n",
    "# 1. Single aggregation function (mean salary per department)\n",
    "mean_salary = grouped[\"Salary\"].mean()\n",
    "print(\"Mean Salary per Department:\\n\", mean_salary, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341d0f94-03a5-4222-9e6c-6ee1547e0a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated stats per Department:\n",
      "              Salary                Bonus             \n",
      "               mean    max    min    sum         mean\n",
      "Department                                           \n",
      "Finance     71000.0  73000  68000  23700  7900.000000\n",
      "IT          72000.0  75000  70000  26300  8766.666667 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Multiple aggregation functions on different columns\n",
    "agg_stats = grouped.agg({\n",
    "    \"Salary\": [\"mean\", \"max\", \"min\"],   # Apply multiple functions on Salary\n",
    "    \"Bonus\": [\"sum\", \"mean\"]            # Apply functions on Bonus\n",
    "})\n",
    "print(\"Aggregated stats per Department:\\n\", agg_stats, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebce34e8-b68f-4c91-8a5e-a562ee62cea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departments with mean salary > 70000:\n",
      "   Department Employee  Salary  Bonus\n",
      "2         IT   Hardik   75000   9000\n",
      "3         IT     Axar   70000   8500\n",
      "5         IT     Gill   71000   8800 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering groups (e.g., keep only departments with mean salary > 71000)\n",
    "\n",
    "# filter keeps rows from groups where the condition is True\n",
    "high_salary_dept = grouped.filter(lambda x: x[\"Salary\"].mean() > 71000)\n",
    "print(\"Departments with mean salary > 70000:\\n\", high_salary_dept, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639cc94-22a9-491a-9e75-4a7462b73db4",
   "metadata": {},
   "source": [
    "#### Difference between grouping/ aggregating in series and dataframes\n",
    "- In grouping, a Series can be grouped only by another Series or index level, while a DataFrame can be grouped by one or more columns.\n",
    "- Series aggregation operates on a single column and returns a Series, whereas DataFrame aggregation can operate on multiple columns and return a DataFrame.\n",
    "- Series is simpler and suitable for single-column data, while DataFrame is more powerful for handling complex, multi-column datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f274d-5789-4b76-998e-0a9e1eb52382",
   "metadata": {},
   "source": [
    "#### 8. Merging DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "378a6786-6584-4f40-8431-9236cd486b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   Employee Department\n",
      "0   Sonali    Finance\n",
      "1     Mahi         IT\n",
      "2   Hardik    Finance\n",
      "3   Kamesh         HR\n"
     ]
    }
   ],
   "source": [
    "## TASK-14\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd  \n",
    "\n",
    "# DataFrame 1: Employee to Department mapping\n",
    "df1 = pd.DataFrame({\n",
    "    \"Employee\": [\"Sonali\", \"Mahi\", \"Hardik\", \"Kamesh\"],   # Employee names\n",
    "    \"Department\": [\"Finance\", \"IT\", \"Finance\", \"HR\"] # Their departments\n",
    "})\n",
    "print(\"DataFrame 1:\\n\",df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89cad409-1279-48df-9b0c-07a383e099eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 2:\n",
      "   Employee  Salary\n",
      "0   Sonali   70000\n",
      "1     Mahi   65000\n",
      "2   Hardik   72000\n",
      "3     Anna   60000\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 2: Employee to Salary mapping\n",
    "df2 = pd.DataFrame({\n",
    "    \"Employee\": [\"Sonali\", \"Mahi\", \"Hardik\", \"Anna\"],  # Some employees (Anna not in df1)\n",
    "    \"Salary\": [70000, 65000, 72000, 60000]         # Salaries\n",
    "})\n",
    "print(\"DataFrame 2:\\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "609ea0ce-4c26-4a35-b455-f9ade879510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Merge:\n",
      "   Employee Department  Salary\n",
      "0   Sonali    Finance   70000\n",
      "1     Mahi         IT   65000\n",
      "2   Hardik    Finance   72000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner Merge: Keeps only employees present in both df1 and df2\n",
    "\n",
    "inner_merge = pd.merge(df1, df2, on=\"Employee\", how=\"inner\")\n",
    "print(\"Inner Merge:\\n\", inner_merge, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55d3c96b-2ff8-4d9f-8e96-6357d6105f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Merge:\n",
      "   Employee Department   Salary\n",
      "0     Anna        NaN  60000.0\n",
      "1   Hardik    Finance  72000.0\n",
      "2   Kamesh         HR      NaN\n",
      "3     Mahi         IT  65000.0\n",
      "4   Sonali    Finance  70000.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outer Merge: Keeps all employees from both df1 and df2\n",
    "\n",
    "# Missing values are filled with NaN\n",
    "outer_merge = pd.merge(df1, df2, on=\"Employee\", how=\"outer\")\n",
    "print(\"Outer Merge:\\n\", outer_merge, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79b2b543-0b67-4003-8e64-31eb875de536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "    EmpID    Name\n",
      "0     10  Sonali\n",
      "1     20    Mahi\n",
      "2     30  Hardik\n"
     ]
    }
   ],
   "source": [
    "## TASK-15\n",
    "\n",
    "# Merging on different key columns\n",
    "# Merging two DataFrames using different column names in each DataFrame by using left_on and right_on.\n",
    "\n",
    "# DataFrame 1: Contains Employee IDs and Names\n",
    "df1 = pd.DataFrame({\n",
    "    \"EmpID\": [10, 20, 30],                # Employee IDs in df1\n",
    "    \"Name\": [\"Sonali\", \"Mahi\", \"Hardik\"]      # Corresponding employee names\n",
    "})\n",
    "print(\"DataFrame 1:\\n\",df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b9628a5-1e67-4f74-b0f5-e73cbac45a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 2:\n",
      "    EmployeeID  Salary\n",
      "0          20   72000\n",
      "1          30   68000\n",
      "2          40   75000\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 2: Contains Employee IDs (with different column name) and Salaries\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"EmployeeID\": [20, 30, 40],           # Employee IDs in df2 (note: column name differs)\n",
    "    \"Salary\": [72000, 68000, 75000]       # Salaries of employees\n",
    "})\n",
    "print(\"DataFrame 2:\\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dba2b6e-64f8-4fe3-a8cc-55c45d5f03d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge on different keys:\n",
      "    EmpID    Name  EmployeeID  Salary\n",
      "0     20    Mahi          20   72000\n",
      "1     30  Hardik          30   68000\n"
     ]
    }
   ],
   "source": [
    "# Merge df1 and df2 using different column names\n",
    "# left_on=\"EmpID\" → column from df1\n",
    "# right_on=\"EmployeeID\" → column from df2\n",
    "# how=\"inner\" → only keeps rows where IDs match in both DataFrames\n",
    "\n",
    "merged_df = pd.merge(df1, df2, left_on=\"EmpID\", right_on=\"EmployeeID\", how=\"inner\")\n",
    "\n",
    "# Print merged DataFrame\n",
    "print(\"Merge on different keys:\\n\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b0599e5-bf18-4d51-b4a1-e065a1538d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge using indexes:\n",
      "         Salary Department\n",
      "Sonali   50000         HR\n",
      "Hardik   60000         IT\n"
     ]
    }
   ],
   "source": [
    "## TASK-16\n",
    "# Merging using indexes\n",
    "\n",
    "# Instead of merging on columns, you can merge using the row index with left_index=True and right_index=True.\n",
    "\n",
    "df1 = pd.DataFrame({\"Salary\": [50000, 60000]}, index=[\"Sonali\", \"Hardik\"])\n",
    "df2 = pd.DataFrame({\"Department\": [\"HR\", \"IT\"]}, index=[\"Sonali\", \"Hardik\"])\n",
    "\n",
    "# Merge using index\n",
    "merged_index_df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "print(\"Merge using indexes:\\n\", merged_index_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba298f37-c69c-4cb1-a8ad-2064249e6f2f",
   "metadata": {},
   "source": [
    "#### 9. Handling overlapping column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01133df1-127a-440a-a1b2-2df352151f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   Employee  Salary\n",
      "0   Sonali   70000\n",
      "1     Mahi   80000\n"
     ]
    }
   ],
   "source": [
    "## TASK-17\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd  \n",
    "\n",
    "# DataFrame 1: Old salary records of employees\n",
    "df1 = pd.DataFrame({\n",
    "    \"Employee\": [\"Sonali\", \"Mahi\"],       # Employee names\n",
    "    \"Salary\": [70000, 80000]            # Old salary values\n",
    "})\n",
    "print(\"DataFrame 1:\\n\",df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57ffc60a-874d-4721-a530-7d9c94e56df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 2:\n",
      "   Employee  Salary\n",
      "0     Mahi   85000\n",
      "1   Hardik   78000\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 2: New salary records of employees\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"Employee\": [\"Mahi\", \"Hardik\"],       # Notice \"Mahi\" overlaps, \"Hardik\" is new\n",
    "    \"Salary\": [85000, 78000]            # New salary values\n",
    "})\n",
    "print(\"DataFrame 2:\\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79fdd054-4acc-42ed-a61a-8eaf73ee7799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge with custom suffixes:\n",
      "   Employee  Salary_Old  Salary_New\n",
      "0   Hardik         NaN     78000.0\n",
      "1     Mahi     80000.0     85000.0\n",
      "2   Sonali     70000.0         NaN\n"
     ]
    }
   ],
   "source": [
    "# Merge df1 and df2 on \"Employee\"\n",
    "# how=\"outer\" → includes all employees from both DataFrames\n",
    "# suffixes=(\"_Old\", \"_New\") → renames overlapping column \"Salary\" \n",
    "# so they don’t clash, making it Salary_Old and Salary_New\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on=\"Employee\", how=\"outer\", suffixes=(\"_Old\", \"_New\"))\n",
    "# Print merged DataFrame\n",
    "print(\"Merge with custom suffixes:\\n\", merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb44483-1d5b-49e9-9dff-278e26856374",
   "metadata": {},
   "source": [
    "#### 10. Generating Summary Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a7565-7dfb-44cf-88ec-ec93e8259c94",
   "metadata": {},
   "source": [
    "#### Summary table \n",
    "- df.pivot_table(values='NumericColumn', index='RowCategory', columns='ColumnCategory', aggfunc='mean') values → numeric column to summarize\n",
    "- index → row labels\n",
    "- columns → column labels (optional)\n",
    "- aggfunc → aggregation function (mean, sum, count, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13d6be23-379b-41a8-9a0a-fd30c6956c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table Summary:\n",
      " Team              A        B\n",
      "Department                  \n",
      "Finance     70000.0  72000.0\n",
      "IT          65000.0  67000.0\n"
     ]
    }
   ],
   "source": [
    "## TASK-18\n",
    "# Import pandas library\n",
    "import pandas as pd  \n",
    "\n",
    "# Create a sample DataFrame with Department, Team, and Salary\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Department\": [\"Finance\", \"Finance\", \"IT\", \"IT\"],   # Two departments\n",
    "    \"Team\": [\"A\", \"B\", \"A\", \"B\"],                       # Two teams within each department\n",
    "    \"Salary\": [70000, 72000, 65000, 67000]              # Salary values for each team\n",
    "})\n",
    "\n",
    "# Create a pivot table to summarize salaries\n",
    "# values=\"Salary\"   → we are summarizing the Salary column\n",
    "# index=\"Department\" → Departments become row index\n",
    "# columns=\"Team\"     → Teams become column headers\n",
    "# aggfunc=\"mean\"     → average salary is calculated per group\n",
    "\n",
    "summary = df.pivot_table(values=\"Salary\", index=\"Department\", columns=\"Team\", aggfunc=\"mean\")\n",
    "# Print the summary table\n",
    "print(\"Pivot Table Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6088b4b-e4ff-44b2-9237-024457378686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Table (Average Salary):\n",
      " Team              X        Y\n",
      "Department                  \n",
      "Finance     70500.0  72000.0\n",
      "IT          65000.0  67500.0\n"
     ]
    }
   ],
   "source": [
    "## TASK-19\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd  \n",
    "\n",
    "# Create a DataFrame with Department, Team, and Salary\n",
    "df = pd.DataFrame({\n",
    "    \"Department\": [\"Finance\", \"Finance\", \"IT\", \"IT\", \"Finance\", \"IT\"],  # Departments\n",
    "    \"Team\": [\"X\", \"Y\", \"X\", \"Y\", \"X\", \"Y\"],                             # Teams inside each department\n",
    "    \"Salary\": [70000, 72000, 65000, 67000, 71000, 68000]                # Salary values\n",
    "})\n",
    "\n",
    "# Create a pivot table to summarize the average Salary\n",
    "# values=\"Salary\"   → we want to summarize the Salary column\n",
    "# index=\"Department\" → rows will be Departments\n",
    "# columns=\"Team\"     → columns will be Teams (X, Y)\n",
    "# aggfunc=\"mean\"     → average salary is calculated if multiple entries exist\n",
    "\n",
    "summary_table = df.pivot_table(values=\"Salary\", index=\"Department\", columns=\"Team\", aggfunc=\"mean\")\n",
    "# Print the summary pivot table\n",
    "print(\"Summary Table (Average Salary):\\n\", summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c94eedd-ebf4-4d75-94dc-c1cc0a9c1fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table with Multiple Aggregations:\n",
      "                mean              sum            max       \n",
      "Team              X        Y       X       Y      X      Y\n",
      "Department                                                \n",
      "Finance     70500.0  72000.0  141000   72000  71000  72000\n",
      "IT          65000.0  67500.0   65000  135000  65000  68000\n"
     ]
    }
   ],
   "source": [
    "## TASK-20\n",
    "# Pivot Table with Multiple Aggregation Functions\n",
    "\n",
    "# applying more than one aggregation function at once using a list:\n",
    "summary_table_multi = df.pivot_table(\n",
    "    values=\"Salary\",\n",
    "    index=\"Department\",\n",
    "    columns=\"Team\",\n",
    "    aggfunc=[\"mean\", \"sum\", \"max\"]\n",
    ")\n",
    "print(\"Pivot Table with Multiple Aggregations:\\n\", summary_table_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63256e91-d2b3-48f4-a216-70636a6cc244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table with Missing Values Filled:\n",
      " Team              X        Y\n",
      "Department                  \n",
      "Finance     70500.0  72000.0\n",
      "IT          65000.0  67500.0\n"
     ]
    }
   ],
   "source": [
    "## TASK-21\n",
    "\n",
    "# Handling Missing Data\n",
    "# Pivot tables automatically fill missing combinations with NaN.\n",
    "\n",
    "# Replace missing values with fill_value\n",
    "summary_table_fill = df.pivot_table(\n",
    "    values=\"Salary\",\n",
    "    index=\"Department\",\n",
    "    columns=\"Team\",\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")\n",
    "print(\"Pivot Table with Missing Values Filled:\\n\", summary_table_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7e63d18-2985-4d1f-8ad8-2974a85049ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivalent using groupby + unstack:\n",
      " Team              X        Y\n",
      "Department                  \n",
      "Finance     70500.0  72000.0\n",
      "IT          65000.0  67500.0\n"
     ]
    }
   ],
   "source": [
    "## TASK-22\n",
    "\n",
    "# Grouping vs Pivot Tables\n",
    "# Pivot tables are essentially groupby + aggregation + reshape in one step.\n",
    "# They are easier to read when summarizing across two categorical variables.\n",
    "\n",
    "# Equivalent using groupby\n",
    "grouped = df.groupby([\"Department\", \"Team\"])[\"Salary\"].mean().unstack()\n",
    "print(\"Equivalent using groupby + unstack:\\n\", grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84492d-0485-4a67-b28f-5885e45e600c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
